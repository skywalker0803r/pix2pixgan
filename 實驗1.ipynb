{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utJLd78UZPa_",
        "outputId": "c4ab86ea-616a-461d-fce0-5d817dcf0eda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
            "  warnings.warn(\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ],
      "source": [
        "# example of pix2pix gan for satellite to map image-to-image translation\n",
        "# example of pix2pix gan for satellite to map image-to-image translation\n",
        "from numpy import load\n",
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy.random import randint\n",
        "#from tensorflow import keras \n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "from tensorflow.keras.models import Model,  load_model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Conv1D, UpSampling1D\n",
        "# from keras.layers import Conv2D\n",
        "# from keras.layers import Conv2DTranspose\n",
        "from tensorflow.keras.layers import LeakyReLU,ZeroPadding1D\n",
        "from tensorflow.keras.layers import ReLU\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import MaxPooling1D\n",
        "from tensorflow.keras.layers import Add\n",
        "\n",
        "#--- 20210820:存檔錄加上日期 ---#\n",
        "import datetime\n",
        "from time import time\n",
        "import os\n",
        "import sys\n",
        "\n",
        "\n",
        "# define the discriminator model# 定義判別器模型\n",
        "def define_discriminator(image_shape):\n",
        "    # weight initialization權重初始化\n",
        "    init = RandomNormal(stddev=0.02)\n",
        "    # source image input 源圖像輸入\n",
        "    in_src_image = Input(shape=image_shape)\n",
        "    # target image input 目標圖像輸入\n",
        "    in_target_image = Input(shape=image_shape)\n",
        "    # concatenate images channel-wise 按通道連接圖像\n",
        "    merged = Concatenate()([in_src_image, in_target_image]) #merged 合併 \n",
        "    # C64\n",
        "    d = Conv1D(64, 4, strides=2, padding='same', kernel_initializer=init)(merged)\n",
        "    # d = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged)\n",
        "    d = LeakyReLU(alpha=0.2)(d)\n",
        "    # C128\n",
        "    d = Conv1D(128, 4, strides=2, padding='same', kernel_initializer=init)(d)\n",
        "    # d = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
        "    d = BatchNormalization()(d)\n",
        "    d = LeakyReLU(alpha=0.2)(d)\n",
        "    # C256\n",
        "    d = Conv1D(256, 4, strides=2, padding='same', kernel_initializer=init)(d)\n",
        "    # d = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
        "    d = BatchNormalization()(d)\n",
        "    d = LeakyReLU(alpha=0.2)(d)\n",
        "    # C512\n",
        "    d = Conv1D(512, 4, strides=2, padding='same', kernel_initializer=init)(d)\n",
        "    # d = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
        "    d = BatchNormalization()(d)\n",
        "    d = LeakyReLU(alpha=0.2)(d)\n",
        "    # second last output layer\n",
        "    d = Conv1D(512, 4, padding='same', kernel_initializer=init)(d)\n",
        "    # d = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n",
        "    d = BatchNormalization()(d)\n",
        "    d = LeakyReLU(alpha=0.2)(d)\n",
        "    # patch output\n",
        "    d = Conv1D(1, 4, padding='same', kernel_initializer=init)(d)\n",
        "    # d = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n",
        "    patch_out = Activation('sigmoid')(d)\n",
        "    # define model\n",
        "    model = Model([in_src_image, in_target_image], patch_out)\n",
        "    # compile model\n",
        "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.5])\n",
        "    return model\n",
        "model = define_discriminator((10,10,3))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def generate_input_data(image_shape):\n",
        "    # 生成隨機的源圖像和目標圖像\n",
        "    src_image = np.random.random(image_shape)\n",
        "    target_image = np.random.random(image_shape)\n",
        "    return [src_image, target_image]\n",
        "\n",
        "# 生成一個輸入資料\n",
        "input_data = np.array(generate_input_data((1,10, 10, 3)))\n",
        "target_image = np.array(generate_input_data((1,10, 10, 3)))\n",
        "predictions = model.predict([input_data[0], target_image[0]])\n",
        "predictions.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TW5TQ53aUnW",
        "outputId": "f42c5ce7-4b06-48af-8640-76d6a96d6bed"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58faa0040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 283ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 10, 1, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, image_shape):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        in_channels = image_shape[0]\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, in_src_image, in_target_image):\n",
        "        merged = torch.cat((in_src_image, in_target_image), dim=-1)\n",
        "        print(merged.shape)\n",
        "        output = self.model(merged)\n",
        "        return output\n",
        "model = Discriminator((1, 1, 100, 100))\n",
        "import numpy as np\n",
        "def generate_input_data(image_shape):\n",
        "    # 生成隨機的源圖像和目標圖像\n",
        "    src_image = np.random.random(image_shape)\n",
        "    target_image = np.random.random(image_shape)\n",
        "    return [src_image, target_image]\n",
        "input_data = generate_input_data((1, 1, 100, 100))  # Set the number of channels to 1\n",
        "target_image = generate_input_data((1, 1, 100, 100))  # Set the number of channels to 1\n",
        "predictions = model(torch.FloatTensor(input_data[0]), torch.FloatTensor(target_image[0]))\n",
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXYNN16objs-",
        "outputId": "9efbe077-c964-49b6-e938-bdb7e50fe700"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 100, 200])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0.5755, 0.5750, 0.6497, 0.6327, 0.5123, 0.6442, 0.5410, 0.6694,\n",
              "           0.5607, 0.6365, 0.6483],\n",
              "          [0.5547, 0.6836, 0.4459, 0.4319, 0.5463, 0.5634, 0.5797, 0.5581,\n",
              "           0.3968, 0.6621, 0.3627],\n",
              "          [0.5635, 0.4801, 0.5313, 0.5427, 0.5513, 0.5401, 0.7156, 0.5752,\n",
              "           0.6434, 0.6097, 0.5944],\n",
              "          [0.4976, 0.6121, 0.5637, 0.6088, 0.6037, 0.4627, 0.6364, 0.4505,\n",
              "           0.6125, 0.3340, 0.5124],\n",
              "          [0.5690, 0.7199, 0.4382, 0.6627, 0.5186, 0.5586, 0.6566, 0.5177,\n",
              "           0.4470, 0.4945, 0.6430]]]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KUa3y0cPetYf"
      },
      "execution_count": 85,
      "outputs": []
    }
  ]
}